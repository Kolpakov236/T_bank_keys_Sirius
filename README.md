# T_bank_keys_Sirius

**Авторазметка**

Взяли 3 модели с huggingface: для zero-shot классификации, генерации и извлечения признаков. Признаки и zero-shot будем использовать тогда, когда они будут уверенны в предсказаниях, а для остальных случаев будем генерировать ответ. Для задач выбрали модели, работающие с русским языком. Для генерации используем large версию, потому что нет необходимости обрабатывать каждый запрос ей.

Создаем ансамбль методов классификации. Считаем ключевы слова, если набирается порог уверенности, то сохраняем метку, иначе переходим к zero-shot. zero-shot содержит коэффициент уверенности, т.е. на каждый ответ выводится вероятность принадлежности этой категории. Гиперпараметром ставим порог, если он набирается, то оставляем предложенную категорю, предпоследним способом проверки будет способ основанный на косинусном сходстве между эмбеддингом текста и ключевыми словами для данной категории, иначе подаем на вход LLM-классификатору, где в промпте прописываем конкретные примеры, для лучшей генерации.

**Модели классификации**

**BERT_LORA**

Первым делом попробуем обучить классификатор на нескольких полносвязных слоях с извлечением признаков с помощью bert модели. Для русского языка есть несколько хороших реализаций берт, но для начала можно попробовать DeepPavlov

Так как для валидации авторазметки LLM моделью мной использовалась ручная валидация выборки в 100 объектов, я заметил сильный дисбаланс классов, поэтому обучить классификатор качественно получится лишь на некоторых категориях, в которых возможно достать нужную часть данных. А для правильной выборки без перевеса в сторону одежды использую RandomOverSampler

По стандарту в классификаторе ставим полносвязный слой и слой выхода, после проб определился уровень, необходимый для dropout.
Для BERT возьмем коэффициент для шага, чтобы не влиять сильно на смещение в пользу отдельных классов при создании признаков классификатору.

По результатам видно, что модель иногда путает детские товары и одежду, отсутствие товара и одежду. Это очевидно, ведь этих классов больше всего, а в товарах для детей пояляется и одежда, как, например, в одежде описывается текстиль. По итогу на LORA дообучении с 2-мя слоями nn удалось достичь f1 = 0.79, что неплохо, учитывая, что мы сильно не прорабатывали модель, а лишь поработали с дисбалансом классов.

**FULL RE-TRAING**

Ранее мы уже пробовали LORA с дообучением слоев внимания, попробуем разморозить все параметры, чтобы улучшить результаты, также поэксперементируем с моделью, взяв rubert-tiny2, для обучения оставим только один слой классификации, чтобы не прийти к переобучению.

Получаем результат чуть лучше, чем в предыдущий раз (0.82 против 0.79) Weighted F1. Сохраним веса и выход, но все равно будем пробовать другие подход.

**MLP с извлечением признаков из BERT**

Дальше чисто ради эксперимента попробучем создать классический многослойный персептрон, но для эмбеддингов используем тот же BERT, то есть по сути сделаем Feature Transfer. Такая модель будет сильно чувствительна к дисбалансу, поэтому с помощью RandomOverSampler дополним малые категории.

Не удивительно, что обычное извлечение признаков не дало лучших результатов (f1 0.76), но ради интереса стоило его попробовать, так как в данных многие отзывы содержат ключевые слова, которые выделяют их. Да и в целом смысл отзывов обычно находится на поверхности, поэтому качественными признаками их разделить возможно.

**LSTM**
Интересно также попробовать LSTM модель, тексты не слишком длинные, поэтому такой подход тоже может показать результаты, хотя опять же странно будет его сравнивать с берт, в котором технологию 2018 года не удалось превзойти до настоящего времени. Подготовку данных оставим похожей на подход с MLP. В LSTM будем подавать эмбеддинги, а на выходе поставим слой классификации.

**BERT + LSTM**

В конце попробуем самое интересное: взять и совместить оба подхода. В этот раз в LSTM подадим эмбеддинги, созданные с помощью энкодера.
Модель явно переобучилась из-за своей сложности, но показала неплохой результат. Сейчас я уже не успею ее доработать, но как хорошую идею оставлю здесь.
